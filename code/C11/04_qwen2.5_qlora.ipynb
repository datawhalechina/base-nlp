{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖（如环境已具备可跳过）\n",
        "%pip install -q -U transformers datasets peft bitsandbytes accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using dataset: ./data\\wukong_dataset_20251109_215706.jsonl\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'output'],\n",
              "    num_rows: 183\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, glob, json, datetime, math\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\n",
        "\n",
        "# 基础配置\n",
        "checkpoint_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "artifacts_dir = \"./checkpoints\"\n",
        "data_dir = \"./data\"\n",
        "max_seq_len = 2048\n",
        "seed_num = 42\n",
        "\n",
        "os.makedirs(artifacts_dir, exist_ok=True)\n",
        "\n",
        "# 选择最新训练集（wukong_dataset_*.jsonl）\n",
        "jsonl_files = sorted(glob.glob(os.path.join(data_dir, \"wukong_dataset_*.jsonl\")), key=os.path.getmtime, reverse=True)\n",
        "\n",
        "train_jsonl = jsonl_files[0]\n",
        "print(f\"using dataset: {train_jsonl}\")\n",
        "\n",
        "# 加载数据集\n",
        "train_set = load_dataset(\"json\", data_files=train_jsonl, split=\"train\")\n",
        "train_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('<|endoftext|>', '<|im_end|>', 151643, 151645)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 加载分词器（Qwen2.5 特点：使用 chat template）\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_id, trust_remote_code=True)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token, tokenizer.eos_token, tokenizer.pad_token_id, tokenizer.eos_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32ff454552194d58856beaa13af8209c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 4bit 量化（QLoRA）\n",
        "compute_dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
        "bnb_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    checkpoint_id,\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_cfg,\n",
        "    device_map=\"cuda:0\",\n",
        ")\n",
        "base_model.config.use_cache = False\n",
        "base_model.gradient_checkpointing_enable()\n",
        "# k-bit 训练准备（关键，否则反向无 grad）\n",
        "base_model = prepare_model_for_kbit_training(base_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 5,046,272 || all params: 7,620,662,784 || trainable%: 0.0662\n"
          ]
        }
      ],
      "source": [
        "# LoRA 配置（根据 peft 映射获取 Qwen2 的推荐 target_modules）\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING[\"qwen2\"],\n",
        ")\n",
        "peft_model = get_peft_model(base_model, lora_cfg)\n",
        "# 训练前确保输入需要梯度（配合 k-bit 预处理）\n",
        "peft_model.enable_input_require_grads()\n",
        "peft_model.config.use_cache = False\n",
        "peft_model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'labels'],\n",
              "    num_rows: 183\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 构造监督样本：使用 Qwen 对话模板，并仅对 assistant 段落计算 loss\n",
        "from datasets import Dataset\n",
        "\n",
        "def format_sample_for_qwen(record):\n",
        "    instr = (record.get(\"instruction\") or \"\").strip()\n",
        "    ans = (record.get(\"output\") or \"\").strip()\n",
        "    if not instr or not ans:\n",
        "        return {\"input_ids\": [], \"labels\": []}\n",
        "\n",
        "    msgs_no_assist = [\n",
        "        {\"role\": \"system\", \"content\": \"你是《黑神话：悟空》领域助手，回答准确、简明。\"},\n",
        "        {\"role\": \"user\", \"content\": instr},\n",
        "    ]\n",
        "    # prompt（包含 assistant 起始标记）\n",
        "    prompt_ids = tokenizer.apply_chat_template(\n",
        "        msgs_no_assist,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    msgs_full = msgs_no_assist + [{\"role\": \"assistant\", \"content\": ans}]\n",
        "    full_ids = tokenizer.apply_chat_template(\n",
        "        msgs_full,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    # 截断到 max_seq_len\n",
        "    full_ids = full_ids[:max_seq_len]\n",
        "    # 计算分界位置\n",
        "    cut = min(len(prompt_ids), len(full_ids))\n",
        "    labels = [-100] * cut + full_ids[cut:]\n",
        "\n",
        "    return {\"input_ids\": full_ids, \"labels\": labels}\n",
        "\n",
        "proc_train = train_set.map(format_sample_for_qwen, remove_columns=train_set.column_names)\n",
        "proc_train = proc_train.filter(lambda x: len(x[\"input_ids\"]) > 0)\n",
        "proc_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据整理器（按批次 padding，保持 -100 标签）\n",
        "from typing import List, Dict\n",
        "\n",
        "class QwenSftCollator:\n",
        "    def __init__(self, pad_id: int, max_length: int = 2048, ignore_id: int = -100):\n",
        "        self.pad_id = pad_id\n",
        "        self.max_length = max_length\n",
        "        self.ignore_id = ignore_id\n",
        "\n",
        "    def __call__(self, features: List[Dict]):\n",
        "        max_len = max(len(f[\"input_ids\"]) for f in features)\n",
        "        max_len = min(max_len, self.max_length)\n",
        "        input_ids, labels = [], []\n",
        "        for f in features:\n",
        "            ids = f[\"input_ids\"][:max_len]\n",
        "            lbs = f[\"labels\"][:max_len]\n",
        "            pad = max_len - len(ids)\n",
        "            if pad > 0:\n",
        "                ids = ids + [self.pad_id] * pad\n",
        "                lbs = lbs + [self.ignore_id] * pad\n",
        "            input_ids.append(torch.tensor(ids, dtype=torch.long))\n",
        "            labels.append(torch.tensor(lbs, dtype=torch.long))\n",
        "        return {\"input_ids\": torch.stack(input_ids), \"labels\": torch.stack(labels)}\n",
        "\n",
        "collator = QwenSftCollator(pad_id=tokenizer.pad_token_id, max_length=max_seq_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./checkpoints\\\\qwen25_wukong_lora_20251109_234702'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 训练参数与 Trainer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "now_tag = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(artifacts_dir, f\"qwen25_wukong_lora_{now_tag}\")\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=run_dir,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-3,\n",
        "    num_train_epochs=4,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_ratio=0.03,\n",
        "    logging_steps=1,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    optim=\"adamw_torch\",\n",
        "    bf16=torch.cuda.is_available() and torch.cuda.is_bf16_supported(),\n",
        "    fp16=not (torch.cuda.is_available() and torch.cuda.is_bf16_supported()),\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=args,\n",
        "    train_dataset=proc_train,\n",
        "    data_collator=collator,\n",
        ")\n",
        "run_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dalvqw\\.conda\\envs\\peft\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 28:23, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.374500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.385800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.300200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.049800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.970300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.765300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.796100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.233100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.146800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.696800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.535100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.178000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.873700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.864500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.496200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.506400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.334600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.284400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.261300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.203900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.131300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.115900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.109200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.097200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.100100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.048900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.019000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.022900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.012300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.012300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.014300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.048900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainOutput(global_step=92, training_loss=0.5158767711204153, metrics={'train_runtime': 1712.7608, 'train_samples_per_second': 0.427, 'train_steps_per_second': 0.054, 'total_flos': 5254275921334272.0, 'train_loss': 0.5158767711204153, 'epoch': 4.0})\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\tokenizer_config.json',\n",
              " './checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\special_tokens_map.json',\n",
              " './checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\chat_template.jinja',\n",
              " './checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\vocab.json',\n",
              " './checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\merges.txt',\n",
              " './checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\added_tokens.json',\n",
              " './checkpoints\\\\qwen25_wukong_lora_20251109_234702\\\\tokenizer.json')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 开始训练并保存 LoRA 适配器\n",
        "train_output = trainer.train()\n",
        "print(train_output)\n",
        "\n",
        "peft_model.save_pretrained(run_dir)\n",
        "tokenizer.save_pretrained(run_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: 我该怎么成为天命人？\n",
            "A: 想要成为天命之人，首先你需要收集“部分灵根”，然后在特定地点（如石卵处）激活它们，之后才能解锁通往黄风岭、狼烟堡等地点的通行权，并进行后续剧情。\n",
            "------------------------------------------------------------\n",
            "Q: 如何获得并合成出云棍？\n",
            "A: 在“黄风岭-挟魂崖”找到6个佛目珠后，前往“挟魂崖-枕石坪”BOSS石先锋所在区域，使用佛目珠召唤并击败BOSS石敢当，获得材料“铁石心”，之后即可解锁铸造出云棍。\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 推理测试：参考数据集选择两条问题进行生成\n",
        "peft_model.eval()\n",
        "\n",
        "TEST_QUERIES = [\n",
        "    \"我该怎么成为天命人？\",\n",
        "    \"如何获得并合成出云棍？\",\n",
        "]\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer_one(question: str) -> str:\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": \"你是《黑神话：悟空》领域助手，回答准确、简明。\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        msgs,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = input_ids.to(peft_model.device)\n",
        "    gen_ids = peft_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.2,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "    )\n",
        "    out_ids = gen_ids[0, input_ids.shape[-1]:]\n",
        "    return tokenizer.decode(out_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "for q in TEST_QUERIES:\n",
        "    ans = infer_one(q)\n",
        "    print(f\"Q: {q}\\nA: {ans}\\n\" + \"-\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "peft",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
