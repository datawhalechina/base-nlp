{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6ab8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f973309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: Qwen/Qwen3-235B-A22B-Instruct-2507 @ https://api.siliconflow.cn/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# 路径与配置\n",
    "DATA_DIR = \"./data\"\n",
    "SRC_MD = f\"{DATA_DIR}/blackwukong.md\"\n",
    "TS = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT_BASE_JSONL = f\"{DATA_DIR}/wukong_base_{TS}.jsonl\"\n",
    "OUT_JSONL = f\"{DATA_DIR}/wukong_dataset_{TS}.jsonl\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# 注意：为演示方便，这里直接在代码中写入密钥与模型，不推荐在生产环境硬编码敏感信息，建议改用环境变量或密钥管理服务\n",
    "BASE_URL = \"https://api.siliconflow.cn/v1\"\n",
    "MODEL_ID = \"Qwen/Qwen3-235B-A22B-Instruct-2507\"\n",
    "API_KEY = \"sk-xxx\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "print(f\"Using model: {MODEL_ID} @ {BASE_URL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0664337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections=14\n"
     ]
    }
   ],
   "source": [
    "# 读取与切分\n",
    "\n",
    "with open(SRC_MD, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_markdown = f.read()\n",
    "\n",
    "md_src = raw_markdown\n",
    "\n",
    "# 按标题切分；无标题回退按段落\n",
    "matches = list(re.finditer(r\"(?m)^(#{2,3})\\s+(.+)$\", md_src))\n",
    "sections = []\n",
    "if not matches:\n",
    "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", md_src) if len(p.strip()) >= 100]\n",
    "    sections = paras\n",
    "else:\n",
    "    for i, m in enumerate(matches):\n",
    "        s = m.start()\n",
    "        e = matches[i + 1].start() if i + 1 < len(matches) else len(md_src)\n",
    "        block = md_src[s:e].strip()\n",
    "        if len(block) >= 100:\n",
    "            sections.append(block)\n",
    "\n",
    "# 去重保序\n",
    "seen = set()\n",
    "uniq = []\n",
    "for t in sections:\n",
    "    key = re.sub(r\"\\s+\", \" \", t).lower()[:240]\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    uniq.append(t)\n",
    "sections = uniq\n",
    "\n",
    "print(f\"sections={len(sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec436504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教师模型调用与解析\n",
    "\n",
    "SYS_PROMPT = (\n",
    "    \"你是《黑神话：悟空》的资深资料整理者。\"\n",
    "    \"将给定原文片段转写为一条训练样本，严格输出JSON：\"\n",
    "    '{\"instruction\":\"用户问题\",\"output\":\"权威完整答案\"}。'\n",
    "    \"要求：\"\n",
    "    \"1. instruction 是自然语言问题；\"\n",
    "    \"2. output 仅依据原文，不要臆测；\"\n",
    "    \"3. 禁止任何额外说明或代码块。\"\n",
    ")\n",
    "\n",
    "def ask_teacher(block: str) -> str:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": block},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=600,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def parse_json_pair(text: str):\n",
    "    m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
    "    if not m:\n",
    "        raise ValueError(\"教师模型返回非JSON\")\n",
    "    obj = json.loads(m.group(0))\n",
    "    ins = (obj.get(\"instruction\") or \"\").strip()\n",
    "    out = (obj.get(\"output\") or \"\").strip()\n",
    "    if not ins or not out:\n",
    "        raise ValueError(\"缺少必要字段\")\n",
    "    return ins, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base saved: 14 -> ./data/wukong_base_20251109_201117.jsonl\n"
     ]
    }
   ],
   "source": [
    "# 生成基础 instruction/output，并写入 OUT_BASE_JSONL\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_BASE_JSONL), exist_ok=True)\n",
    "base_written = 0\n",
    "\n",
    "with open(OUT_BASE_JSONL, \"w\", encoding=\"utf-8\") as fbase:\n",
    "    for seg in sections:\n",
    "        resp = None\n",
    "        for _attempt in range(3):\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=MODEL_ID,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": seg},\n",
    "                    ],\n",
    "                    temperature=0.2,\n",
    "                    max_tokens=600,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                break\n",
    "            except Exception:\n",
    "                if _attempt == 2:\n",
    "                    resp = None\n",
    "                    break\n",
    "                time.sleep(1.5 ** _attempt + random.random() * 0.3)\n",
    "        if resp is None:\n",
    "            continue\n",
    "        obj = json.loads(resp.choices[0].message.content)\n",
    "        ins = (obj.get(\"instruction\") or \"\").strip()\n",
    "        out = (obj.get(\"output\") or \"\").strip()\n",
    "        if not ins or not out:\n",
    "            continue\n",
    "        fbase.write(json.dumps({\"instruction\": ins, \"output\": out}, ensure_ascii=False) + \"\\n\")\n",
    "        base_written += 1\n",
    "\n",
    "print(f\"base saved: {base_written} -> {OUT_BASE_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: 183 -> ./data/wukong_dataset_20251109_215706.jsonl\n"
     ]
    }
   ],
   "source": [
    "# 读取基础集，进行问法改写并写入最终集 OUT_JSONL（顺序执行，无函数）\n",
    "\n",
    "NUM_VARIANTS = 14\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_JSONL), exist_ok=True)\n",
    "written = 0\n",
    "seen_q = set()\n",
    "\n",
    "# 选择最新的基础集文件\n",
    "base_files = sorted(glob.glob(f\"{DATA_DIR}/wukong_base_*.jsonl\"), key=os.path.getmtime, reverse=True)\n",
    "IN_BASE_JSONL = base_files[0]\n",
    "\n",
    "with open(IN_BASE_JSONL, \"r\", encoding=\"utf-8\") as fr, open(OUT_JSONL, \"w\", encoding=\"utf-8\") as fw:\n",
    "    for line in fr:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        base_q = (obj.get(\"instruction\") or \"\").strip()\n",
    "        answer = (obj.get(\"output\") or \"\").strip()\n",
    "        if not base_q or not answer:\n",
    "            continue\n",
    "\n",
    "        r2 = None\n",
    "        for _attempt in range(3):\n",
    "            try:\n",
    "                r2 = client.chat.completions.create(\n",
    "                    model=MODEL_ID,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"严格输出 JSON 对象：{\\\\\\\"paraphrases\\\\\\\": [\\\\\\\"...\\\\\\\"]}；禁止任何额外文本/代码块/前后缀。若需引号请用中文引号「」或在 JSON 中转义为 \\\\\\\\\\\"。每项必须是可直接回答的等价问法，不改变边界与条件。\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"基础问题：{base_q}\\n数量：{NUM_VARIANTS}\\n输出键：paraphrases\"},\n",
    "                    ],\n",
    "                    temperature=0.6,\n",
    "                    max_tokens=800,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                break\n",
    "            except Exception:\n",
    "                if _attempt == 2:\n",
    "                    r2 = None\n",
    "                    break\n",
    "                time.sleep(1.5 ** _attempt + random.random() * 0.3)\n",
    "        if r2 is None:\n",
    "            continue\n",
    "        obj2 = json.loads(r2.choices[0].message.content)\n",
    "        arr = obj2.get(\"paraphrases\", [])\n",
    "        arr = [x.strip() for x in arr if isinstance(x, str) and x.strip()]\n",
    "        if not arr:\n",
    "            continue\n",
    "\n",
    "        # 规范：以问号结尾并全局去重\n",
    "        for s in arr:\n",
    "            if not s.endswith((\"?\", \"？\")):\n",
    "                s = s.rstrip(\"？?\") + \"？\"\n",
    "            if s in seen_q:\n",
    "                continue\n",
    "            seen_q.add(s)\n",
    "            fw.write(json.dumps({\"instruction\": s, \"output\": answer}, ensure_ascii=False) + \"\\n\")\n",
    "            written += 1\n",
    "\n",
    "print(f\"saved: {written} -> {OUT_JSONL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
